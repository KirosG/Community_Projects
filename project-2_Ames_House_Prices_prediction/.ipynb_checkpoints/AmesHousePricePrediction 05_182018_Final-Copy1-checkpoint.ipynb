{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ames Housing Prices Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I plan to show how to clean, explore, analyze and predict home prices based on permanent house qualities. I used only Linearrgression using total home sqrft ratio with overall qaulity of the house \n",
    "\n",
    "This notebook uses [data from Kaggle](https://www.kaggle.com/c/dsi-us-4-project-2-regression-challenge/data).\n",
    "\n",
    "This is the final submitted [submitted  to Kaggle](https://www.kaggle.com/c/dsi-us-4-project-2-regression-challenge/leaderboard). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This file provide a basic exploration of ames house price dataset\n",
    "# import necessary Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mpl_toolkits\n",
    "import seaborn as sns\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures,StandardScaler\n",
    "import scipy.stats\n",
    "from patsy import dmatrices\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score\n",
    "from sklearn import metrics\n",
    "import sqlite3\n",
    "import os \n",
    "import csv\n",
    "# Configure visual settings:\n",
    "%matplotlib inline\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) \n",
    "plt.style.use('ggplot')\n",
    "np.random.seed(2018)\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data and EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load the data, which is given in csv format in Kaggle for both train and test\n",
    "df = pd.read_csv('./data/train.csv')\n",
    "test = pd.read_csv('./data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.map(lambda x: x.replace(\" \", \"\").replace(\"/\",\"\"))\n",
    "df.head()[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "print(df.dtypes.sort_values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SalePrice'].hist(bins=30)\n",
    "plt.title('sale price distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salePrice = df['SalePrice'].copy()\n",
    "salePrice.sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df.select_dtypes(include=['float64','int64']).iloc[:, 2:].corr()\n",
    "plt.figure(figsize=(12, 12))\n",
    "sns.heatmap(corr, vmax=1, square=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x = 'OverallQual', y = 'SalePrice', data = df, color = 'Orange')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "f, axarr = plt.subplots(3, 2, figsize=(10, 9))\n",
    "price = df.SalePrice.values\n",
    "axarr[0, 0].scatter(df.GrLivArea.values, price)\n",
    "axarr[0, 0].set_title('GrLiveArea')\n",
    "axarr[0, 1].scatter(df.GarageArea.values, price)\n",
    "axarr[0, 1].set_title('GarageArea')\n",
    "axarr[1, 0].scatter(df.TotalBsmtSF.values, price)\n",
    "axarr[1, 0].set_title('TotalBsmtSF')\n",
    "axarr[1, 1].scatter(df['1stFlrSF'].values, price)\n",
    "axarr[1, 1].set_title('1stFlrSF')\n",
    "axarr[2, 0].scatter(df.TotRmsAbvGrd.values, price)\n",
    "axarr[2, 0].set_title('TotRmsAbvGrd')\n",
    "axarr[2, 1].scatter(df.MasVnrArea.values, price)\n",
    "axarr[2, 1].set_title('MasVnrArea')\n",
    "f.text(-0.01, 0.5, 'Sale Price', va='center', rotation='vertical', fontsize = 12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(2, figsize=(9, 7))\n",
    "plt.subplot(211)\n",
    "plt.scatter(df.YearBuilt.values, price)\n",
    "plt.title('YearBuilt')\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.scatter(df.YearRemodAdd.values, price)\n",
    "plt.title('YearRemodAdd')\n",
    "\n",
    "fig.text(-0.01, 0.5, 'Sale Price', va = 'center', rotation = 'vertical', fontsize = 12)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.select_dtypes(include=['object']).columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neighborhood\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x='Neighborhood', y='SalePrice', data=df)\n",
    "xt = plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_nulls(df):\n",
    "    for col in df.columns:\n",
    "        print(\"NaN count: {}, {}, {}\".format(df[col].isnull().sum(), col, df[col].dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_data(df):\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'object':\n",
    "            print(df[col].value_counts())\n",
    "    else:\n",
    "        print(df[col].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_from(df, f_y, f_x, y_upper_limit=None, x_upper_limit=None):\n",
    "    df = df.copy()\n",
    "    df_full = df.loc[np.logical_not(df[f_y].isnull())]\n",
    "    x = df_full.loc[:,f_x]\n",
    "    y = df_full.loc[:,f_y]\n",
    "    plt.scatter(x, y)\n",
    "    plt.xlabel(f_x)\n",
    "    plt.ylabel(f_y)\n",
    "    plt.show()\n",
    "    if x_upper_limit is not None and y_upper_limit is not None:\n",
    "        mask = (x < x_upper_limit) & (y <= y_upper_limit)\n",
    "    else:\n",
    "        mask = np.ones_like(x, dtype=bool)\n",
    "        p = np.polyfit(x[mask], y[mask], 1) # degree 1\n",
    "        df.loc[df[f_y].isnull(), f_y] = np.polyval(p, df.loc[df[f_y].isnull(), f_x])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/train.csv')\n",
    "df.columns = df.columns.map(lambda x: x.replace(\" \", \"\").replace(\"/\",\"\"))\n",
    "df = df.drop(['Order','PID'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_train_test_data(train, test):\n",
    "    \n",
    "    # replace Alley NA with None\n",
    "    train.Alley.fillna('None', inplace=True)\n",
    "    test.Alley.fillna('None', inplace=True)\n",
    "\n",
    "    # replace MasVnrArea na with 0\n",
    "    train.MasVnrArea.fillna(0, inplace=True)\n",
    "    test.MasVnrArea.fillna(0, inplace=True)\n",
    "\n",
    "    # replace NAs from not having a basement, freplace, garage, pool, miscellaneous feature\n",
    "    # fence with None\n",
    "    na_columns = ['BsmtQual', 'BsmtCond', 'BsmtExposure', 'FireplaceQu', 'GarageType', \\\n",
    "               'BsmtFinType1', 'BsmtFinType2', 'GarageYrBlt', 'GarageFinish', \\\n",
    "               'GarageQual', 'GarageCond', 'PoolQC', 'Fence', 'MiscFeature']\n",
    "\n",
    "    for col in na_columns:\n",
    "        train[col].fillna('None', inplace=True)\n",
    "        test[col].fillna('None', inplace=True)\n",
    "\n",
    "    # replace continous  feature NAs \n",
    "    # fill these with zero\n",
    "    fill_zero = ['MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'BsmtFullBath', \n",
    "                 'BsmtHalfBath', 'GarageCars', 'GarageArea']\n",
    "    for col in fill_zero:\n",
    "        train[col].fillna(0, inplace=True)\n",
    "        test[col].fillna(0, inplace=True)\n",
    "\n",
    "    \n",
    "    # replace LotFrontage NA with mean\n",
    "    train.LotFrontage.fillna(train.LotFrontage.mean(), inplace=True)\n",
    "    test.LotFrontage.fillna(test.LotFrontage.mean(), inplace=True)\n",
    "\n",
    "    # apply log to skewed columns\n",
    "    numeric_columns = train._get_numeric_data().columns\n",
    "    skewed = []\n",
    "    for col in numeric_columns:\n",
    "        if (train[col].skew() < -2) or (train[col].skew() > 2):\n",
    "            skewed.append(col)\n",
    "    for col in skewed:\n",
    "        train[col] = train[col] + 1\n",
    "        test[col] = test[col] + 1\n",
    "        train[col] = np.log10(train[col])\n",
    "        test[col] = np.log10(test[col])\n",
    "    \n",
    "    # apply log10 transformation to Sale Price\n",
    "    train.SalePrice = np.log10(train.SalePrice)\n",
    "    \n",
    "     # concatenate dataframes\n",
    "    houses = pd.concat([train.drop('SalePrice', axis=1), test]).reset_index(drop=True)\n",
    "    # get dummy variables\n",
    "    houses_dummy = pd.get_dummies(houses)\n",
    "    # sort by Id to slice out test data accurately\n",
    "    houses_dummy.sort_values(by='Id', inplace=True)\n",
    "    # split train and test data\n",
    "    train_dummy = houses_dummy.iloc[:1459, :].copy()\n",
    "    test_dummy = houses_dummy.iloc[1460:, :].copy()\n",
    "    # add Sale Price column back to train dataframe\n",
    "    train_dummy['SalePrice'] = train.SalePrice\n",
    "    \n",
    "    return train_dummy, test_dummy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dummy, test_dummy = format_train_test_data(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dummy.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "test_dummy.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dummy.shape, test_dummy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dummy.SalePrice.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = train_dummy.iloc[:, train_dummy.columns != 'SalePrice']\n",
    "y = train_dummy.SalePrice\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "def mylog_rmse(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Return log root mean square error\n",
    "    Assumes y is already in log scale\n",
    "    Input: tuple of True values of y, Predicted values of y\n",
    "    Output: log rmse\n",
    "    \"\"\"\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    return np.sqrt(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skewed_columns(train):\n",
    "    numeric_columns = train._get_numeric_data().columns\n",
    "    skewed_columns = []\n",
    "    for column in numeric_columns:\n",
    "        if column in X_train.columns:\n",
    "            if (X_train[column].skew() < -2) or (X_train[column].skew() > 2):\n",
    "                skewed_columns.append(column)\n",
    "    return skewed_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skewed_columns(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(10,5))\n",
    "\n",
    "for column, ax in zip(skewed_columns(train), axes.ravel()):\n",
    "    ax.hist(train_dummy[column])\n",
    "    ax.set_title('Histogram of \\n{}'.format(column), fontsize=8)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(10,5))\n",
    "\n",
    "for column, ax in zip(skewed_columns(train), axes.ravel()):\n",
    "    ax.scatter(train_dummy[column], train_dummy.SalePrice)\n",
    "    ax.set_title('Sale Price vs \\n{}'.format(column), fontsize=8)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> As can be seen above most of the  extreme values seem to appear in variables that most houses do not possess hence many zeroes and scattered extreme values<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outliers of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dummy.GrLivArea.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dummy.Id.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(train_dummy.GrLivArea, train_dummy.SalePrice, alpha=0.5)\n",
    "ax.set(xlabel='Gr Liv Area', ylabel='Sale Price')\n",
    "for point_id, x, y in zip(train_dummy.Id, train_dummy.GrLivArea, train_dummy.SalePrice):\n",
    "    if x > 7000:\n",
    "        # outliers -> GrLivArea above 7000\n",
    "        ax.annotate(point_id, xy=(x, y), xytext=(x+1000, y+0.5), arrowprops=dict(arrowstyle = '->'))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# removing these points\n",
    "train_dummy = train_dummy.loc[train_dummy.GrLivArea < 4000, :].copy()\n",
    "train_dummy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.linear_model import Ridge, ElasticNet, Lasso\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge with standardized X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_grid_search(estimator, param_grid):\n",
    "    \n",
    "    grid_search = GridSearchCV(estimator, \n",
    "                               param_grid, \n",
    "                               n_jobs=-1, \n",
    "                               cv=5, \n",
    "                               scoring='mse')\n",
    "    %time grid_search.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Test set log adj RMSE: {:.5f}\".format(mylog_rmse(y_test, grid_search.predict(X_test))))\n",
    "    print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
    "    print(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))\n",
    "\n",
    "    results = pd.DataFrame(grid_search.cv_results_)\n",
    "    \n",
    "    return grid_search, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(estimator, \n",
    "                               param_grid, \n",
    "                               n_jobs=-1, \n",
    "                               cv=5, \n",
    "                               scoring='mylog_rmse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid={'ridge__alpha': [0.1, 1, 10] + list(range(20,200,20)) + [1000]\n",
    "           }\n",
    "grid_search, results = do_grid_search(estimator = make_pipeline(StandardScaler(), Ridge(random_state=0)), \n",
    "                                      param_grid = param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def do_grid_search(estimator, param_grid):\n",
    "#     grid_search = GridSearchCV(estimator, param_grid, n_jobs=-1, cv=5, scoring='neg_mean_squared_error')\n",
    "#     %time grid_search.fit(X_train, y_train)\n",
    "#     print(\"Test set log adj RMSE: {:.5f}\".format(mylog_rmse(y_test, grid_search.predict(X_test))))\n",
    "#     print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
    "#     print(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))\n",
    "#     results = pd.DataFrame(grid_search.cv_results_)\n",
    "#     return grid_search, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_grid_search(estimator = make_pipeline(StandardScaler(), Ridge(random_state=0)), \n",
    "                                      param_grid = param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid={'ridge__alpha': [0.1, 1, 10] + list(range(20,200,20)) + [1000]\n",
    "           }\n",
    "grid_search, results = do_grid_search(estimator = make_pipeline(StandardScaler(), Ridge(random_state=0)), \n",
    "                                      param_grid = param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
